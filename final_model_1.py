# -*- coding: utf-8 -*-
"""Final_Model_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rLNuVF8qTwgzWNqhBt6P3azoSkbtNFHQ
"""

import pandas as pd
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
import numpy as np
from tensorflow import feature_column
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from joblib import dump, load
import matplotlib.pyplot as plt
import seaborn as sn
import tkinter as tk
import pandas as pd
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
import numpy as np
from tensorflow import feature_column
import pickle
import joblib
from joblib import dump,load
import pickle
import tempfile
from tensorflow.keras.models import Sequential, load_model, save_model, Model
from tensorflow.keras.layers import Dense
from tensorflow.python.keras.layers import deserialize, serialize
from tensorflow.python.keras.saving import saving_utils

import pandas as pd
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from joblib import dump, load
import tkinter as tk
import joblib
from joblib import dump,load

names = ['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER','CLASS']

df = pd.read_csv('Crime.csv')
df.head()

df.head()
df.info()
df.describe()

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=100)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=10)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=10)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=120)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=200)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X=df[['TYPE','DATE','MONTH','YEAR','TIME','AREA','NEAR TO MAIN ROAD OR NOT','NEAR TO COMMERCIAL CENTRE OR NOT','POPULATION OF AREA','KNOWLEDGE OF HOUSE OWNER']]  # Features
y=df['CLASS']  # Labels

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

clf=RandomForestClassifier(n_estimators=150)

#Train the model
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf.fit(X_train,y_train)

df.describe()

df.info()

df.replace('?',0, inplace=True)

scaler = MinMaxScaler(feature_range=(0, 1))
normalizedData = scaler.fit_transform(df)

# Bagged Decision Trees
from sklearn import model_selection
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

X = normalizedData[:,0:10]
Y = normalizedData[:,10]

from sklearn import model_selection

kfold = model_selection.KFold(n_splits=10, random_state=7)

from sklearn.ensemble import AdaBoostClassifier
seed = 7
num_trees = 20
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)
results = model_selection.cross_val_score(clf, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

# Voting Ensemble for Classification
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier
from sklearn.neighbors import KNeighborsClassifier

kfold = model_selection.KFold(n_splits=10, random_state=seed)

estimators = []
model1 = RandomForestClassifier()
estimators.append(('clf', model1))
model2 = LogisticRegression()
estimators.append(('logistic', model2))
model3 = KNeighborsClassifier()
estimators.append(('knn',model3))

# create the ensemble model
ensemble = VotingClassifier(estimators)
results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

# calculates precision for 1:100 dataset with 90 tp and 30 fp
from sklearn.metrics import precision_score
# define actual
act_pos = [1 for _ in range(100)]
act_neg = [0 for _ in range(10000)]
y_true = act_pos + act_neg
# define predictions
pred_pos = [0 for _ in range(10)] + [1 for _ in range(90)]
pred_neg = [1 for _ in range(30)] + [0 for _ in range(9970)]
y_pred = pred_pos + pred_neg
# calculate prediction
precision = precision_score(y_true, y_pred, average='binary')
print('Precision: %.3f' % precision)

# calculates recall for 1:100 dataset with 90 tp and 10 fn
from sklearn.metrics import recall_score
# define actual
act_pos = [1 for _ in range(100)]
act_neg = [0 for _ in range(10000)]
y_true = act_pos + act_neg
# define predictions
pred_pos = [0 for _ in range(10)] + [1 for _ in range(90)]
pred_neg = [0 for _ in range(10000)]
y_pred = pred_pos + pred_neg
# calculate recall
recall = recall_score(y_true, y_pred, average='binary')
print('Recall: %.3f' % recall)

# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp
from sklearn.metrics import f1_score
# define actual
act_pos = [1 for _ in range(100)]
act_neg = [0 for _ in range(10000)]
y_true = act_pos + act_neg
# define predictions
pred_pos = [0 for _ in range(5)] + [1 for _ in range(95)]
pred_neg = [1 for _ in range(55)] + [0 for _ in range(9945)]
y_pred = pred_pos + pred_neg
# calculate score
score = f1_score(y_true, y_pred, average='binary')
print('F-Measure: %.3f' % score)

results = model_selection.cross_val_score(model2, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

results = model_selection.cross_val_score(model3, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

from sklearn.ensemble import AdaBoostClassifier
seed = 7
num_trees = 20
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)
results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

from sklearn.ensemble import AdaBoostClassifier
seed = 7
num_trees = 20
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)
results = model_selection.cross_val_score(model2, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

from sklearn.ensemble import AdaBoostClassifier
seed = 7
num_trees = 20
kfold = model_selection.KFold(n_splits=10, random_state=seed)
model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)
results = model_selection.cross_val_score(model3, X, Y, cv=kfold)
print("Accuracy : ",results.mean())

ensemble.fit(X_train,y_train)

joblib.dump(ensemble,"classifier")

precision = precision_score(y_test, Y)
print('Precision: %f' % precision)

recall = recall_score(y_test, Y)
print('Recall: %f' % recall)

f1 = f1_score(y_test, yhat_classes)
print('F1 score: %f' % f1)

accuracy = accuracy_score(y_test, y_pred)
print('Accuracy: %f' % accuracy)

precision = precision_score(y_test, y_pred)
print('Precision: %f' % precision)

# recall: tp / (tp + fn)
recall = recall_score(y_test, y_pred)
print('Recall: %f' % recall)

# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(y_test, y_pred)
print('F1 score: %f' % f1)

# tkinter GUI
root= tk.Tk()

canvas1 = tk.Canvas(root, width = 1000, height = 650)
canvas1.pack()

# TYPE
label1 = tk.Label(root, text='                                                   TYPE:')
canvas1.create_window(100, 100, window=label1)

entry1 = tk.Entry (root)
canvas1.create_window(270, 100, window=entry1)

# DATE
label2 = tk.Label(root, text='                                      DATE:')
canvas1.create_window(120, 120, window=label2)

entry2 = tk.Entry (root)
canvas1.create_window(270, 120, window=entry2)

# MONTH
label3 = tk.Label(root, text='                   MONTH:')
canvas1.create_window(140, 140, window=label3)

entry3 = tk.Entry (root)
canvas1.create_window(270, 140, window=entry3)

# YEAR
label4 = tk.Label(root, text='           YEAR:')
canvas1.create_window(160, 160, window=label4)

entry4 = tk.Entry (root)
canvas1.create_window(270, 160, window=entry4)

# TIME
label5 = tk.Label(root, text='TIME:')
canvas1.create_window(180, 180, window=label5)

entry5 = tk.Entry (root)
canvas1.create_window(270, 180, window=entry5)

# AREA
label6 = tk.Label(root, text='                 AREA:                               ')
canvas1.create_window(200, 200, window=label6)

entry6 = tk.Entry (root)
canvas1.create_window(270, 200, window=entry6)

# MAINROAD
label7 = tk.Label(root, text='MAINROAD:                                      ')
canvas1.create_window(220, 220, window=label7)

entry7 = tk.Entry (root)
canvas1.create_window(270, 220, window=entry7)

# COMMERCIAL CENTER
label8 = tk.Label(root, text='COMMERCIAL_CENTER_PRESENCE:                                                                                          ')
canvas1.create_window(240, 240, window=label8)

entry8 = tk.Entry (root)
canvas1.create_window(270, 240, window=entry8)

# POPULATION
label9 = tk.Label(root, text='POPULATION:                                                                    ')
canvas1.create_window(260, 260, window=label9)

entry9 = tk.Entry (root)
canvas1.create_window(270, 260, window=entry9)

# KNOWLEDGE OF HOUSE OWNER
label10 = tk.Label(root, text='KNOWLEDGE_OF_OWNER:                                                                                                       ')
canvas1.create_window(280, 280, window=label10)

entry10 = tk.Entry (root)
canvas1.create_window(270, 280, window=entry10)

def values():
    global TYPE
    TYPE = float(entry1.get())

    global DATE
    DATE = float(entry2.get())

    global MONTH
    MONTH = float(entry3.get())

    global YEAR
    YEAR = float(entry4.get())

    global TIME
    TIME = float(entry5.get())

    global AREA
    AREA = float(entry6.get())

    global NEAR_TO_MAIN_ROAD_OR_NOT
    NEAR_TO_MAIN_ROAD_OR_NOT = float(entry7.get())

    global NEAR_TO_COMMERCIAL_CENTRE_OR_NOT
    NEAR_TO_COMMERCIAL_CENTRE_OR_NOT = float(entry8.get())

    global POPULATION_OF_AREA
    POPULATION_OF_AREA = float(entry9.get())

    global KNOWLEDGE_OF_HOUSE_OWNER
    KNOWLEDGE_OF_HOUSE_OWNER = float(entry10.get())

    Prediction_result  = ('  Predicted Result: ', clf.predict([[TYPE,DATE,MONTH,YEAR,TIME,AREA,NEAR_TO_MAIN_ROAD_OR_NOT,NEAR_TO_COMMERCIAL_CENTRE_OR_NOT,POPULATION_OF_AREA,KNOWLEDGE_OF_HOUSE_OWNER]]))
    label_Prediction = tk.Label(root, text= Prediction_result, bg='sky blue')
    canvas1.create_window(400, 400, window=label_Prediction)

button1 = tk.Button (root, text='      Predict      ',command=values, bg='green', fg='white', font=11)
canvas1.create_window(270, 320, window=button1)

root.mainloop()